{"cells":[{"cell_type":"markdown","metadata":{"id":"35T9-nzHHSgV"},"source":["# Woche 9 Exercise 1: NN Classification of MNIST"]},{"cell_type":"markdown","metadata":{"id":"KZps2EVQHSgd"},"source":["## MNIST Data\n","We return to the MNIST data set on handwritten digits to compare non-linear classification algorithms ...   "]},{"cell_type":"markdown","metadata":{"id":"xKOyK1UTHSgk"},"source":["### Task\n","* Build a \"fully connected\" neural network for MNIST\n","  * Hint: use the code \"[Example: MLP for MNIST](https://colab.research.google.com/github/keuperj/DataScience23/blob/main/week_9/keras_intro.ipynb)\" from the tutorial to get started.\n","  * why do we need to use \"flatten\"\n","* evaluate different network layouts (number of layers, number of neurons in layer)\n","* evaluate different hyper-parameter settings (learning rate)\n","\n","Keras API: https://keras.io/api/"]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras"],"metadata":{"id":"c1YZdpgxl-8F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#get data\n","(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"etbyKnMLmGpz","outputId":"0f9a3a53-8916-46a0-82f3-677787b691ab","executionInfo":{"status":"ok","timestamp":1683287995265,"user_tz":-120,"elapsed":717,"user":{"displayName":"Bianca Lamm","userId":"03697538926795876163"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["# Build a simple model\n","inputs = keras.Input(shape=(28, 28))\n","l1 = keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n","l2 = keras.layers.Flatten()(l1)\n","# NOTE: in Keras \"fully connected\", aka matrix multiplication layers are called \"dense layers\"\n","l3 = keras.layers.Dense(128, activation=\"tanh\")(l2)\n","l4 = keras.layers.Dense(128, activation=\"tanh\")(l3)\n","outputs = keras.layers.Dense(10, activation=\"softmax\")(l4)\n","model = keras.Model(inputs, outputs)\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2DEaccrUya8P","executionInfo":{"status":"ok","timestamp":1683288239052,"user_tz":-120,"elapsed":981,"user":{"displayName":"Bianca Lamm","userId":"03697538926795876163"}},"outputId":"935a5cf7-8ae3-4b65-a54c-419a1895f8f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 28, 28)]          0         \n","                                                                 \n"," rescaling (Rescaling)       (None, 28, 28)            0         \n","                                                                 \n"," flatten (Flatten)           (None, 784)               0         \n","                                                                 \n"," dense (Dense)               (None, 128)               100480    \n","                                                                 \n"," dense_1 (Dense)             (None, 128)               16512     \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 118,282\n","Trainable params: 118,282\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")"],"metadata":{"id":"HpZZlB0yy6IP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model for 1 epoch from Numpy data\n","batch_size = 64\n","print(\"Fit on NumPy data\")\n","history = model.fit(x_train, y_train, batch_size=batch_size, epochs=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iY5AfXMNy73n","executionInfo":{"status":"ok","timestamp":1683288858715,"user_tz":-120,"elapsed":6326,"user":{"displayName":"Bianca Lamm","userId":"03697538926795876163"}},"outputId":"bca4604e-34e8-4b45-ec38-50ea31d8167f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fit on NumPy data\n","938/938 [==============================] - 5s 5ms/step - loss: 0.2857\n"]}]},{"cell_type":"code","source":["print(history.history)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JWy_pHHK1h7w","executionInfo":{"status":"ok","timestamp":1683288893460,"user_tz":-120,"elapsed":2,"user":{"displayName":"Bianca Lamm","userId":"03697538926795876163"}},"outputId":"37989bf7-4056-4deb-df7c-7812df873173"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'loss': [0.2857133746147156]}\n"]}]},{"cell_type":"markdown","source":["why do we need to use \"flatten\"<br>\n","Flatten layer is used to make the multidimensional input one-dimensional, commonly used in the transition from the convolution layer to the full connected layer."],"metadata":{"id":"OwAf-NZo1afg"}},{"cell_type":"code","source":["# Build a simple model\n","inputs = keras.Input(shape=(28, 28))\n","l1 = keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n","l2 = keras.layers.Flatten()(l1)\n","# NOTE: in Keras \"fully connected\", aka matrix multiplication layers are called \"dense layers\"\n","l3 = keras.layers.Dense(128, activation=\"tanh\")(l2) # layer 1\n","l4 = keras.layers.Dense(64, activation=\"tanh\")(l3) # layer 2\n","l4 = keras.layers.Dense(32, activation=\"tanh\")(l3) # layer 3\n","outputs = keras.layers.Dense(10, activation=\"softmax\")(l4)\n","model = keras.Model(inputs, outputs)\n","model.summary()\n","\n","# Compile the model\n","model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n","\n","# Train the model for 1 epoch from Numpy data\n","batch_size = 64\n","print(\"Fit on NumPy data\")\n","history = model.fit(x_train, y_train, batch_size=batch_size, epochs=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wzkz_hqO1fBg","executionInfo":{"status":"ok","timestamp":1683289096392,"user_tz":-120,"elapsed":7719,"user":{"displayName":"Bianca Lamm","userId":"03697538926795876163"}},"outputId":"954af97d-7723-4c7a-af28-157cedda84c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 28, 28)]          0         \n","                                                                 \n"," rescaling_1 (Rescaling)     (None, 28, 28)            0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 128)               100480    \n","                                                                 \n"," dense_5 (Dense)             (None, 32)                4128      \n","                                                                 \n"," dense_6 (Dense)             (None, 10)                330       \n","                                                                 \n","=================================================================\n","Total params: 104,938\n","Trainable params: 104,938\n","Non-trainable params: 0\n","_________________________________________________________________\n","Fit on NumPy data\n","938/938 [==============================] - 7s 6ms/step - loss: 0.3387\n"]}]},{"cell_type":"code","source":["print(history.history)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"buqsitxm2SBy","executionInfo":{"status":"ok","timestamp":1683289098523,"user_tz":-120,"elapsed":2,"user":{"displayName":"Bianca Lamm","userId":"03697538926795876163"}},"outputId":"21fb9d26-1ac0-4c92-c8c4-6504caeaffb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'loss': [0.33871346712112427]}\n"]}]},{"cell_type":"code","source":["# Build a simple model\n","inputs = keras.Input(shape=(28, 28))\n","l1 = keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n","l2 = keras.layers.Flatten()(l1)\n","# NOTE: in Keras \"fully connected\", aka matrix multiplication layers are called \"dense layers\"\n","l3 = keras.layers.Dense(128, activation=\"tanh\")(l2) # layer 1\n","l4 = keras.layers.Dense(64, activation=\"tanh\")(l3) # layer 2\n","l4 = keras.layers.Dense(32, activation=\"tanh\")(l3) # layer 3\n","outputs = keras.layers.Dense(10, activation=\"softmax\")(l4)\n","model = keras.Model(inputs, outputs)\n","model.summary()\n","\n","# Compile the model\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss=\"sparse_categorical_crossentropy\")\n","\n","# Train the model for 1 epoch from Numpy data\n","batch_size = 64\n","print(\"Fit on NumPy data\")\n","history = model.fit(x_train, y_train, batch_size=batch_size, epochs=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"un93aIs32Uaw","executionInfo":{"status":"ok","timestamp":1683289535499,"user_tz":-120,"elapsed":5749,"user":{"displayName":"Bianca Lamm","userId":"03697538926795876163"}},"outputId":"d9704792-6eda-4224-d6b0-319a6c8f54ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 28, 28)]          0         \n","                                                                 \n"," rescaling_2 (Rescaling)     (None, 28, 28)            0         \n","                                                                 \n"," flatten_2 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_7 (Dense)             (None, 128)               100480    \n","                                                                 \n"," dense_9 (Dense)             (None, 32)                4128      \n","                                                                 \n"," dense_10 (Dense)            (None, 10)                330       \n","                                                                 \n","=================================================================\n","Total params: 104,938\n","Trainable params: 104,938\n","Non-trainable params: 0\n","_________________________________________________________________\n","Fit on NumPy data\n","938/938 [==============================] - 5s 5ms/step - loss: 0.3222\n"]}]},{"cell_type":"code","source":["print(history.history)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"djtnu1OI3_eZ","executionInfo":{"status":"ok","timestamp":1683289537879,"user_tz":-120,"elapsed":3,"user":{"displayName":"Bianca Lamm","userId":"03697538926795876163"}},"outputId":"488e0b1f-9d92-4176-82d3-1ffa7de69856"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'loss': [0.3222421407699585]}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5g0HhYpo3_sK"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[{"file_id":"1Q9QcwWfo-OcYOtO7f_NBvPLwOEW0z-a-","timestamp":1683786914332},{"file_id":"https://github.com/keuperj/DataScience23/blob/main/week_9/keras_NN_classification.ipynb","timestamp":1683287282932}]}},"nbformat":4,"nbformat_minor":0}