{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBZeCiBqEDfI"
      },
      "source": [
        "# Week 5: Returning to MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOn9BluIEDfP"
      },
      "source": [
        "## MNIST Data\n",
        "In these exercises we are using the MNIST data set on handwritten digits to compare supervised classification algorithms...   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zJ7lalQcEDfR"
      },
      "outputs": [],
      "source": [
        "#imports \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGa9W6i8EDfU"
      },
      "outputs": [],
      "source": [
        "# Load data from https://www.openml.org/d/554\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOF5FoTmEDfV"
      },
      "source": [
        "#the full MNIST data set contains 70k samples of digits 0-9 as 28*28 gray scale images (represented as 784 dim vectors)\n",
        "np.shape(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKcbruhwEDfV"
      },
      "outputs": [],
      "source": [
        "np.shape(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz8GlWEzEDfX"
      },
      "outputs": [],
      "source": [
        "X[1,:].reshape((28,28)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJoytF9IEDfZ"
      },
      "source": [
        "### E1.1: Use SkLearn methods to split the MNIST data into random train and test sets. Use 60k samples for training.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Mko30b5EDfb"
      },
      "source": [
        "### E1.2: Train models on the train data.\n",
        "Train the following models with default parameters on the train data.\n",
        "* [Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) (assuming a Gaussian distribution of the data)\n",
        "* [Simple linear model](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)\n",
        "   * use ``loss='log'`` to reproduce our logistic loss function \n",
        "* [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
        "\n",
        "Compare the training and test accuracy (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) and [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) for all three models."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H-XY8Dr1Ljga"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "5_a_Classification.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}